<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Reason-RFT</title>
    <meta name="description" content="Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>



<body onload="SubmissionVidep();">
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="">Huajie Tan</a><sup>1,2,*</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Yuheng Ji</a><sup>2,3,4,*</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Xiaoshuai Hao</a><sup>2,*,&dagger;</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Minglan Lin</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Pengwei Wang</a><sup>2,&dagger;</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank">Shanghang Zhang</a><sup>1,2,&nbsp;<span style="font-family: serif;">✉</span></sup>
                            </span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block" style="font-size: 0.9em;"><sup>1</sup>State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University</span>
                            <span class="author-block" style="font-size: 0.9em;"><sup>2</sup>Beijing Academy of Artificial Intelligence</span>
                            <span class="author-block" style="font-size: 0.9em;"><sup>3</sup>Institute of Automation, Chinese Academy of Sciences</span>
                            <span class="author-block" style="font-size: 0.9em;"><sup>4</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences</span>
                            <span class="author-block" style="font-size: 0.9em;"><sup>*</sup>Equal contribution <sup>&dagger;</sup>Project leaders <sup>&nbsp;<span style="font-family: serif;">✉</span></sup>Corresponding author</span>
                        </div>
                        <div class="column has-text-centered">
                            <!-- ArXiv link -->
                            <span class="link-block">
                                <a target="_blank" href="https://tanhuajie.github.io/ReasonRFT" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-file"></i></span>
                                    <span>ArXiv</span>
                                </a>
                            </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                                <a target="_blank" href="https://tanhuajie.github.io/ReasonRFT" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fab fa-github"></i></span>
                                    <span>Code</span>
                                </a>
                            </span>
                            <!-- Dataset Link. -->
                            <span class="link-block">
                                <a target="_blank" href="https://tanhuajie.github.io/ReasonRFT" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-database"></i></span>
                                    <span>Dataset</span>
                                </a>
                            </span>
                            <span class="link-block">
                            <a target="_blank" href="https://tanhuajie.github.io/ReasonRFT" class="external-link button is-normal is-rounded is-dark">
                                <span class="icon"><i class="fas fa-check"></i></span>
                                <span>Checkpoints</span>
                            </a>
                        </span>
                            <span class="link-block">
                                <a target="_blank" href="https://tanhuajie.github.io/ReasonRFT" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-laptop"></i></span>
                                    <span>Demo</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

<!-- Teaser and Abstract -->
    <div class="columns is-centered">
        <div class="container">
          <div class="content has-text-centered">
            <h2 class="title is-3">Reason-RFT Overview</h2>
  
            <div class="box m-5" >
              <div class="content has-text-centered">
                <figure>
                    <img src="images/teasor.png" alt="teaser" width="90%">
                    <figcaption><strong>Overview of Reason-RFT.</strong> Compared to traditional SFT-based methods, 
                        our proposed Reason-RFT framework demonstrates superior generalization in visual reasoning tasks, 
                        excelling in reasoning improvement, out-of-domain performance, and data efficiency.
                    </figcaption>
                </figure>
              </div>
            </div>
          </div>
        </div>
    </div>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Visual reasoning abilities play a crucial role in understanding complex multimodal data, advancing both domain-specific applications and artificial general intelligence (AGI).
                            Existing methods improve VLM reasoning via Chain-of-Thought (CoT) supervised fine-tuning, using meticulously annotated training data to enhance visual reasoning capabilities.
                            However, this training paradigm may lead to overfitting and cognitive rigidity, restricting the model's ability to transfer visual reasoning skills across domains and limiting its real-world applicability.
                            To address these limitations, we propose <strong>Reason-RFT</strong>, a novel reinforcement fine-tuning framework that significantly enhances generalization capabilities in visual reasoning tasks.
                            <strong>Reason-RFT</strong> introduces a two-phase training framework for visual reasoning: (1) Supervised Fine-Tuning (SFT) with curated Chain-of-Thought (CoT) data activates the reasoning potential of Vision-Language Models (VLMs), followed by (2) Group Relative Policy Optimization (GRPO)-based reinforcement learning that generates multiple reasoning-response pairs, significantly enhancing generalization in visual reasoning tasks.
                            To evaluate <strong>Reason-RFT</strong>'s visual reasoning capabilities, we reconstructed a comprehensive dataset spanning visual counting, structure perception, and spatial transformation, serving as a benchmark to systematically assess visual cognition, geometric understanding, and spatial generalization.
                            Experimental results demonstrate Reasoning-RFT's three key advantages: <strong>(1) Performance Enhancement:</strong> achieving state-of-the-art results across multiple tasks, outperforming both open-source and proprietary models; 
                            <strong>(2) Generalization Superiority:</strong> consistently maintaining robust performance across diverse tasks and domains, outperforming alternative training paradigms.
                            <strong>(3) Data Efficiency:</strong> excelling in few-shot learning scenarios while surpassing full-dataset SFT baselines.
                        </p>
                    </div>
                </div>
            </div>
            <!-- /Abstract -->
        </div>
    </section>
    
    <div class="columns is-centered">
        <div class="container">
          <div class="content has-text-centered">
            <h2 class="title is-3">Reason-RFT Pipeline</h2>
  
            <div class="box m-5" >
              <div class="content has-text-centered">
                <figure>
                    <img src="images/pipeline.png" alt="pipeline" width="70%">
                    <figcaption><strong>Framework of Reason-RFT.</strong> 
                        Reason-RFT introduces a two-phase training framework for visual reasoning. 
                        First, Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) reasoning activates the model's domain-specific reasoning capabilities using a high-quality visual reasoning dataset in stage 1. 
                        Subsequently, in stage 2, Group Relative Policy Optimization (GRPO) enhances reasoning capabilities, enabling Reason-RFT to achieve superior generalization by pushing the model's reasoning limits. 
                        Specifically, reward evaluation consists of format reward and three different types of accuracy reward.
                    </figcaption>
                </figure>
              </div>
            </div>
          </div>
        </div>
    </div>


    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows is-centered">
                <h2 class="title is-3 has-text-centered">Evaluation Results</h2>
    
                <div class="box m-5" >
                    <div class="content has-text-centered">
                        <figure>
                            <img src="images/eval.png" alt="evaluation" width="80%">
                            <figcaption>Results on three visual reasoning tasks. The best results among different training paradigms are highlighted in bold, while the
                                second-best results are underlined. “ID” denotes in-domain test data, and “OOD” denotes out-of-domain test data.
                            </figcaption>
                        </figure>
                    </div>
                </div>
    
                <div class="box m-5">
                    <div id="results-carousel" class="carousel results-carousel">  
                    
                      <div class="content has-text-centered">
                        <img src="images/appx_res_2b.png" alt="" width="70%"/>
                        <p style="margin-bottom: 30px;">Results Comparison for 2B model.</p>
                      </div>
    
                      <div class="content has-text-centered">
                        <img src="images/appx_res_7b.png" alt="" width="70%"/>
                        <p style="margin-bottom: 30px;">Results Comparison for 7B model.</p>
                      </div>
                    </div>
                </div>
            </div>

            <div class="rows is-centered">
                <h2 class="title is-3 has-text-centered">Training Insights</h2>
    
                <div class="box m-5">
                    <div id="results-carousel" class="carousel results-carousel">  
                    
                      <div class="content has-text-centered">
                        <p class="content has-text-justified" style="text-align: left;">
                            <strong>Transient Adaptation Gap.</strong> 
                            This phenomenon refers to the temporary performance drop observed during the initial phase of training process with Reason-RFT-Zero. 
                            As the model transitions from directly outputting answers to generating structured reasoning processes, 
                            it experiences a brief adaptation difficulty, leading to a sharp performance decline followed by gradual recovery. As shown in (a), 
                            which illustrates the training process of Reason-RFT-Zero on the CLEVR-MATH, both ID and OOD test performances exhibit this sharp drop and recovery within the first 100 steps (highlighted in the zoomed-in section). 
                            We further investigate this phenomenon through a case study, as depicted in (b).
                        </p>
                        <img src="images/phon_1.png" alt="" width="70%"/>
                        <p style="margin-bottom: 30px;">Transient Adaptation Gap.</p>
                      </div>
    
                      <div class="content has-text-centered">
                        <p class="content has-text-justified" style="text-align: left;">
                            <strong>Greedy Reward Stratification.</strong> 
                            This phenomenon describes the model's tendency during Reason-RFT-Zero training to prioritize easier rewards (e.g., Format Reward) over harder ones (e.g., Accuracy Reward). 
                            As shown in Figure, the model's Reasoning Token Length initially decreases, then gradually increases before stabilizing. This behavior coincides with the Format Reward reaching its initial peak and the Accuracy Reward entering its rapid growth phase. 
                            We infer that the model simplifies its outputs early on to quickly adapt to the structured response format, reducing Reasoning Token Length. 
                            Once the Format Reward is maximized, the model shifts focus to improving accuracy, increasing Reasoning Token Length.
                        </p>
                        <img src="images/phon_2.png" alt="" width="70%"/>
                        <p style="margin-bottom: 30px;">Greedy Reward Stratification.</p>
                      </div>

                      <div class="content has-text-centered">
                        <p class="content has-text-justified" style="text-align: left;">
                            <strong>Reasoning Redundancy.</strong>
                            This phenomenon refers to the significant difference in Reasoning Token Length between models trained under different paradigms. 
                            For example, in the Structure Perception task, Reason-RFT and Reason-RFT-Zero achieve comparable final test accuracy, but Reason-RFT exhibits notably longer Reasoning Token Length, as shown in Figure. 
                            This occurs because the CoT data used in Reason-RFT's Reasoning Activation phase, often distilled from stronger models (e.g., GPT-4o), leads the model to learn longer reasoning chains during CoT-SFT. 
                            During the Reasoning Reinforcement phase, the model retains these lengthy chains due to the lack of penalties or incentives for response length. In contrast, Reason-RFT-Zero, which lacks CoT data, stabilizes at a shorter Reasoning Token Length through exploration. 
                            We hypothesize that Reason-RFT's longer reasoning chains may be unnecessary for the current task difficulty, introducing redundant computational overhead. 
                            Experiments limiting Reasoning Token Length during inference for Reason-RFT-trained models show stable performance until a certain threshold, partially confirming Reasoning Redundancy in specific tasks.
                        </p>
                        <img src="images/phon_3.png" alt="" width="70%"/>
                        <p style="margin-bottom: 30px;">Reasoning Redundancy.</p>
                      </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows is-centered">
                <h2 class="title is-3 has-text-centered">Case Study on Visual Counting Task</h2>
    
                <div class="box m-5">
                    <div id="results-carousel" class="carousel results-carousel">  
                    
                      <div class="content has-text-centered">
                        <img src="images/sep_0_1.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 1 on Visual Counting task.</p>
                      </div>
    
                      <div class="content has-text-centered">
                        <img src="images/sep_0_2.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 2 on Visual Counting task.</p>
                      </div>

                    </div>
                </div>
            </div>

            <div class="rows is-centered">
                <h2 class="title is-3 has-text-centered">Case Study on Structure Perception Task</h2>
    
                <div class="box m-5">
                    <div id="results-carousel" class="carousel results-carousel">  
                    
                      <div class="content has-text-centered">
                        <img src="images/sep_case1.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 1 on Structure Perception task.</p>
                      </div>
    
                      <div class="content has-text-centered">
                        <img src="images/sep_case2.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 2 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case3.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 3 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case4.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 4 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case5.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 5 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case6.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 6 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case7.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 7 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case8.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 8 on Structure Perception task.</p>
                      </div>


                      <div class="content has-text-centered">
                        <img src="images/sep_case9.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 9 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case10.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 10 on Structure Perception task.</p>
                      </div>


                      <div class="content has-text-centered">
                        <img src="images/sep_case11.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 11 on Structure Perception task.</p>
                      </div>

                      <div class="content has-text-centered">
                        <img src="images/sep_case12.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 12 on Structure Perception task.</p>
                      </div>
                    </div>
                </div>
            </div>

            <div class="rows is-centered">
                <h2 class="title is-3 has-text-centered">Case Study on Spatial Transformation Task</h2>
    
                <div class="box m-5">
                    <div id="results-carousel" class="carousel results-carousel">  
                    
                      <div class="content has-text-centered">
                        <img src="images/spatial_case1.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 1 on Spatial Transformation task.</p>
                      </div>
    
                      <div class="content has-text-centered">
                        <img src="images/spatial_case2.png" alt="" width="60%"/>
                        <p style="margin-bottom: 30px;">Example 2 on Spatial Transformation task.</p>
                      </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

</body>
</html>
